[package]
name = "llm-connector"
version = "0.2.3"
edition = "2021"
authors = ["lipi"]
description = "Minimal Rust library for LLM protocol abstraction. Supports 4 protocols (OpenAI, Anthropic, Aliyun, Ollama) with unified interface, and dynamic model discovery."
license = "MIT"
readme = "README.md"
repository = "https://github.com/lipish/llm-connector"
keywords = ["llm", "ai", "protocol", "openai", "anthropic"]
categories = ["api-bindings", "web-programming::http-client"]

[lib]
name = "llm_connector"
path = "src/lib.rs"

[features]
default = ["reqwest"]
# HTTP client support
reqwest = ["dep:reqwest", "dep:tokio", "dep:futures-util"]
# Streaming support
streaming = ["reqwest", "dep:pin-project-lite"]
# Configuration support
config = ["dep:serde_yaml"]
# YAML configuration support
yaml = ["config", "dep:serde_yaml"]
# TOML configuration support (placeholder for future use)
toml = ["config"]

[dependencies]
# Core serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Core dependencies
async-trait = "0.1"
chrono = { version = "0.4", features = ["serde"] }
thiserror = "1.0"
rand = "0.8"
log = "0.4"

# HTTP client (optional)
reqwest = { version = "0.11", features = ["json", "stream"], optional = true }
tokio = { version = "1.0", features = ["rt"], optional = true }
futures-util = { version = "0.3", optional = true }

# Streaming utilities (optional)
pin-project-lite = { version = "0.2", optional = true }

# Configuration (optional)
serde_yaml = { version = "0.9", optional = true }



[dev-dependencies]
tokio = { version = "1.0", features = ["full"] }
tokio-test = "0.4"
wiremock = "0.6"
serde_yaml = "0.9"
