//! Zhipu ç¨³å®šæ€§æµ‹è¯•ç¤ºä¾‹
//!
//! ä¸“é—¨ç”¨äºæµ‹è¯•å’Œè¯Šæ–­ Zhipu API çš„ç¨³å®šæ€§é—®é¢˜

use llm_connector::{LlmClient, types::{ChatRequest, Message}, error::LlmConnectorError};
use std::time::{Duration, Instant};
use tokio::time::timeout;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ” Zhipu ç¨³å®šæ€§æµ‹è¯•å·¥å…·\n");

    let api_key = std::env::var("ZHIPU_API_KEY")
        .expect("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPU_API_KEY");

    println!("API Key: {}...", &api_key[..8.min(api_key.len())]);

    // å¯ç”¨è°ƒè¯•æ¨¡å¼
    std::env::set_var("LLM_DEBUG_REQUEST_RAW", "1");
    std::env::set_var("LLM_DEBUG_RESPONSE_RAW", "1");

    // æµ‹è¯•1: åŸºæœ¬è¿æ¥æµ‹è¯•
    println!("\nğŸ“‹ æµ‹è¯•1: åŸºæœ¬è¿æ¥æµ‹è¯•");
    test_basic_connection(&api_key).await;

    // æµ‹è¯•2: ä¸åŒè¶…æ—¶è®¾ç½®æµ‹è¯•
    println!("\nğŸ“‹ æµ‹è¯•2: ä¸åŒè¶…æ—¶è®¾ç½®æµ‹è¯•");
    test_different_timeouts(&api_key).await;

    // æµ‹è¯•3: å¹¶å‘è¯·æ±‚æµ‹è¯•
    println!("\nğŸ“‹ æµ‹è¯•3: å¹¶å‘è¯·æ±‚æµ‹è¯•");
    test_concurrent_requests(&api_key).await;

    // æµ‹è¯•4: é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
    println!("\nğŸ“‹ æµ‹è¯•4: é•¿æ—¶é—´è¿è¡Œæµ‹è¯•");
    test_long_running(&api_key).await;

    // æµ‹è¯•5: æµå¼å“åº”ç¨³å®šæ€§æµ‹è¯•
    #[cfg(feature = "streaming")]
    {
        println!("\nğŸ“‹ æµ‹è¯•5: æµå¼å“åº”ç¨³å®šæ€§æµ‹è¯•");
        test_streaming_stability(&api_key).await;
    }

    println!("\nğŸ¯ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

/// åŸºæœ¬è¿æ¥æµ‹è¯•
async fn test_basic_connection(api_key: &str) {
    let client = LlmClient::zhipu_with_timeout(api_key, 10000); // 10ç§’è¶…æ—¶
    
    let request = ChatRequest {
        model: "glm-4-flash".to_string(),
        messages: vec![Message::user("æµ‹è¯•è¿æ¥")],
        max_tokens: Some(10),
        ..Default::default()
    };

    let start = Instant::now();
    match client.chat(&request).await {
        Ok(response) => {
            println!("   âœ… åŸºæœ¬è¿æ¥æˆåŠŸ ({:?})", start.elapsed());
            println!("   å“åº”: {}", response.choices[0].message.content);
        }
        Err(e) => {
            println!("   âŒ åŸºæœ¬è¿æ¥å¤±è´¥ ({:?}): {}", start.elapsed(), e);
            analyze_error(&e);
        }
    }
}

/// æµ‹è¯•ä¸åŒè¶…æ—¶è®¾ç½®
async fn test_different_timeouts(api_key: &str) {
    let timeout_configs = vec![
        ("5ç§’", 5000),
        ("15ç§’", 15000),
        ("30ç§’", 30000),
        ("60ç§’", 60000),
    ];

    for (name, timeout_ms) in timeout_configs {
        println!("   æµ‹è¯•è¶…æ—¶è®¾ç½®: {}", name);
        let client = LlmClient::zhipu_with_timeout(api_key, timeout_ms);
        
        let request = ChatRequest {
            model: "glm-4-flash".to_string(),
            messages: vec![Message::user("ç®€å•å›ç­”ï¼šä½ å¥½")],
            max_tokens: Some(20),
            ..Default::default()
        };

        let start = Instant::now();
        match client.chat(&request).await {
            Ok(_) => {
                println!("     âœ… {} è¶…æ—¶æµ‹è¯•æˆåŠŸ ({:?})", name, start.elapsed());
            }
            Err(e) => {
                println!("     âŒ {} è¶…æ—¶æµ‹è¯•å¤±è´¥ ({:?}): {}", name, start.elapsed(), e);
                if matches!(e, LlmConnectorError::TimeoutError(_)) {
                    println!("     â° ç¡®è®¤ä¸ºè¶…æ—¶é”™è¯¯");
                }
            }
        }
    }
}

/// å¹¶å‘è¯·æ±‚æµ‹è¯•
async fn test_concurrent_requests(api_key: &str) {
    let client = LlmClient::zhipu_with_timeout(api_key, 20000);
    let concurrent_count = 3;

    println!("   å¯åŠ¨ {} ä¸ªå¹¶å‘è¯·æ±‚...", concurrent_count);

    let mut handles = Vec::new();
    for i in 0..concurrent_count {
        let client = client.clone();
        let handle = tokio::spawn(async move {
            let request = ChatRequest {
                model: "glm-4-flash".to_string(),
                messages: vec![Message::user(&format!("å¹¶å‘æµ‹è¯• #{}", i + 1))],
                max_tokens: Some(15),
                ..Default::default()
            };

            let start = Instant::now();
            let result = client.chat(&request).await;
            (i + 1, start.elapsed(), result)
        });
        handles.push(handle);
    }

    let mut success_count = 0;
    let mut failure_count = 0;

    for handle in handles {
        match handle.await {
            Ok((id, duration, Ok(_))) => {
                println!("     âœ… å¹¶å‘è¯·æ±‚ #{} æˆåŠŸ ({:?})", id, duration);
                success_count += 1;
            }
            Ok((id, duration, Err(e))) => {
                println!("     âŒ å¹¶å‘è¯·æ±‚ #{} å¤±è´¥ ({:?}): {}", id, duration, e);
                failure_count += 1;
            }
            Err(e) => {
                println!("     ğŸ’¥ å¹¶å‘è¯·æ±‚ä»»åŠ¡å¤±è´¥: {}", e);
                failure_count += 1;
            }
        }
    }

    println!("   å¹¶å‘æµ‹è¯•ç»“æœ: æˆåŠŸ {}, å¤±è´¥ {}", success_count, failure_count);
}

/// é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
async fn test_long_running(api_key: &str) {
    let client = LlmClient::zhipu_with_timeout(api_key, 15000);
    let test_duration = Duration::from_secs(60); // 1åˆ†é’Ÿæµ‹è¯•
    let interval = Duration::from_secs(10); // æ¯10ç§’ä¸€æ¬¡è¯·æ±‚

    println!("   å¼€å§‹é•¿æ—¶é—´è¿è¡Œæµ‹è¯• ({}ç§’)...", test_duration.as_secs());

    let start_time = Instant::now();
    let mut request_count = 0;
    let mut success_count = 0;
    let mut failure_count = 0;

    while start_time.elapsed() < test_duration {
        request_count += 1;
        
        let request = ChatRequest {
            model: "glm-4-flash".to_string(),
            messages: vec![Message::user(&format!("é•¿æ—¶é—´æµ‹è¯• #{}", request_count))],
            max_tokens: Some(10),
            ..Default::default()
        };

        let request_start = Instant::now();
        match timeout(Duration::from_secs(20), client.chat(&request)).await {
            Ok(Ok(_)) => {
                println!("     âœ… è¯·æ±‚ #{} æˆåŠŸ ({:?})", request_count, request_start.elapsed());
                success_count += 1;
            }
            Ok(Err(e)) => {
                println!("     âŒ è¯·æ±‚ #{} å¤±è´¥ ({:?}): {}", request_count, request_start.elapsed(), e);
                failure_count += 1;
            }
            Err(_) => {
                println!("     â° è¯·æ±‚ #{} è¶…æ—¶ ({:?})", request_count, request_start.elapsed());
                failure_count += 1;
            }
        }

        // ç­‰å¾…ä¸‹ä¸€æ¬¡è¯·æ±‚
        if start_time.elapsed() < test_duration {
            tokio::time::sleep(interval).await;
        }
    }

    println!("   é•¿æ—¶é—´æµ‹è¯•ç»“æœ:");
    println!("     æ€»è¯·æ±‚æ•°: {}", request_count);
    println!("     æˆåŠŸ: {} ({:.1}%)", success_count, (success_count as f64 / request_count as f64) * 100.0);
    println!("     å¤±è´¥: {} ({:.1}%)", failure_count, (failure_count as f64 / request_count as f64) * 100.0);
}

/// æµå¼å“åº”ç¨³å®šæ€§æµ‹è¯•
#[cfg(feature = "streaming")]
async fn test_streaming_stability(api_key: &str) {
    use futures_util::StreamExt;

    let client = LlmClient::zhipu_with_timeout(api_key, 20000);
    
    let request = ChatRequest {
        model: "glm-4-flash".to_string(),
        messages: vec![Message::user("è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—")],
        max_tokens: Some(100),
        ..Default::default()
    };

    println!("   å¼€å§‹æµå¼å“åº”æµ‹è¯•...");
    let start = Instant::now();
    
    match client.chat_stream(&request).await {
        Ok(mut stream) => {
            let mut chunk_count = 0;
            let mut total_content = String::new();
            
            while let Some(chunk_result) = stream.next().await {
                match chunk_result {
                    Ok(chunk) => {
                        chunk_count += 1;
                        if let Some(content) = chunk.get_content() {
                            total_content.push_str(content);
                            print!("{}", content);
                        }
                    }
                    Err(e) => {
                        println!("\n     âŒ æµå¼å“åº”é”™è¯¯: {}", e);
                        break;
                    }
                }
            }
            
            println!("\n   âœ… æµå¼å“åº”å®Œæˆ ({:?})", start.elapsed());
            println!("     æ¥æ”¶åˆ° {} ä¸ªæ•°æ®å—", chunk_count);
            println!("     æ€»å†…å®¹é•¿åº¦: {} å­—ç¬¦", total_content.len());
        }
        Err(e) => {
            println!("   âŒ æµå¼å“åº”å¯åŠ¨å¤±è´¥ ({:?}): {}", start.elapsed(), e);
            analyze_error(&e);
        }
    }
}

/// åˆ†æé”™è¯¯å¹¶æä¾›å»ºè®®
fn analyze_error(error: &LlmConnectorError) {
    println!("     ğŸ” é”™è¯¯åˆ†æ:");
    match error {
        LlmConnectorError::TimeoutError(_) => {
            println!("       - è¿™æ˜¯è¶…æ—¶é”™è¯¯ï¼Œå¯èƒ½çš„åŸå› :");
            println!("         1. ç½‘ç»œå»¶è¿Ÿè¿‡é«˜");
            println!("         2. Zhipu æœåŠ¡å™¨å“åº”æ…¢");
            println!("         3. è¶…æ—¶è®¾ç½®è¿‡çŸ­");
            println!("       - å»ºè®®: å¢åŠ è¶…æ—¶æ—¶é—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥");
        }
        LlmConnectorError::ConnectionError(_) => {
            println!("       - è¿™æ˜¯è¿æ¥é”™è¯¯ï¼Œå¯èƒ½çš„åŸå› :");
            println!("         1. ç½‘ç»œè¿æ¥é—®é¢˜");
            println!("         2. Zhipu æœåŠ¡å™¨ä¸å¯è¾¾");
            println!("         3. DNS è§£æé—®é¢˜");
            println!("       - å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®");
        }
        LlmConnectorError::AuthenticationError(_) => {
            println!("       - è¿™æ˜¯è®¤è¯é”™è¯¯ï¼Œå¯èƒ½çš„åŸå› :");
            println!("         1. API Key æ— æ•ˆæˆ–è¿‡æœŸ");
            println!("         2. è´¦æˆ·ä½™é¢ä¸è¶³");
            println!("         3. API Key æƒé™ä¸è¶³");
            println!("       - å»ºè®®: æ£€æŸ¥ API Key å’Œè´¦æˆ·çŠ¶æ€");
        }
        LlmConnectorError::RateLimitError(_) => {
            println!("       - è¿™æ˜¯é¢‘ç‡é™åˆ¶é”™è¯¯");
            println!("       - å»ºè®®: é™ä½è¯·æ±‚é¢‘ç‡æˆ–å‡çº§è´¦æˆ·");
        }
        _ => {
            println!("       - å…¶ä»–é”™è¯¯ç±»å‹: {}", error);
            println!("       - å»ºè®®: å¯ç”¨è¯¦ç»†è°ƒè¯•æ—¥å¿—æŸ¥çœ‹æ›´å¤šä¿¡æ¯");
        }
    }
}
