//! Anthropic æµå¼å“åº”ç¤ºä¾‹
//!
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¢å¼ºçš„ Anthropic æµå¼å“åº”åŠŸèƒ½

#[cfg(feature = "streaming")]
use llm_connector::{LlmClient, types::{ChatRequest, Message}};
#[cfg(feature = "streaming")]
use futures_util::StreamExt;

#[cfg(feature = "streaming")]
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¤– Anthropic æµå¼å“åº”ç¤ºä¾‹\n");

    // éœ€è¦ Anthropic API key
    let api_key = std::env::var("ANTHROPIC_API_KEY")
        .unwrap_or_else(|_| {
            println!("âŒ è¯·è®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡");
            std::process::exit(1);
        });

    // åˆ›å»º Anthropic å®¢æˆ·ç«¯
    let client = LlmClient::anthropic(&api_key);

    // 1. æ™®é€šèŠå¤©è¯·æ±‚
    println!("ğŸ’¬ æ™®é€šèŠå¤©è¯·æ±‚:");
    let request = ChatRequest {
        model: "claude-3-5-sonnet-20241022".to_string(),
        messages: vec![
            Message::user("è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æµå¼å“åº”çš„ä¼˜åŠ¿ã€‚")
        ],
        max_tokens: Some(200),
        ..Default::default()
    };

    match client.chat(&request).await {
        Ok(response) => {
            println!("   Claude å›å¤: {}\n", response.choices[0].message.content);
        }
        Err(e) => {
            println!("   âŒ èŠå¤©é”™è¯¯: {}\n", e);
        }
    }

    // 2. æµå¼èŠå¤©è¯·æ±‚
    println!("ğŸŒŠ æµå¼èŠå¤©è¯·æ±‚:");
    println!("   Claude æ­£åœ¨æµå¼å›å¤...");

    match client.chat_stream(&request).await {
        Ok(mut stream) => {
            print!("   ");
            while let Some(chunk) = stream.next().await {
                match chunk {
                    Ok(streaming_response) => {
                        if let Some(content) = streaming_response.get_content() {
                            print!("{}", content);
                            // å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒºï¼Œä»¥ä¾¿å®æ—¶æ˜¾ç¤º
                            use std::io::{self, Write};
                            io::stdout().flush().unwrap();
                        }

                        // æ£€æŸ¥æ˜¯å¦å®Œæˆ
                        if let Some(finish_reason) = streaming_response.choices.first()
                            .and_then(|c| c.finish_reason.as_ref()) {
                            if finish_reason == "stop" {
                                println!("\n\n   âœ… æµå¼å“åº”å®Œæˆï¼");
                                if let Some(usage) = streaming_response.usage {
                                    println!("   ğŸ“Š ä½¿ç”¨ç»Ÿè®¡:");
                                    println!("     è¾“å…¥ä»¤ç‰Œ: {}", usage.prompt_tokens);
                                    println!("     è¾“å‡ºä»¤ç‰Œ: {}", usage.completion_tokens);
                                    println!("     æ€»ä»¤ç‰Œ: {}", usage.total_tokens);
                                }
                            }
                        }
                    }
                    Err(e) => {
                        println!("\n   âŒ æµå¼å“åº”é”™è¯¯: {}", e);
                        break;
                    }
                }
            }
        }
        Err(e) => {
            println!("   âŒ æµå¼è¯·æ±‚é”™è¯¯: {}", e);
        }
    }

    println!("\nâœ… ç¤ºä¾‹å®Œæˆï¼");
    println!("\nğŸ’¡ æç¤º:");
    println!("   - æµå¼å“åº”æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œå¯ä»¥å®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹");
    println!("   - ç‰¹åˆ«é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆå’Œäº¤äº’å¼åº”ç”¨");
    println!("   - æ–°çš„ Anthropic æµå¼å®ç°æ­£ç¡®å¤„ç†äº†å¤æ‚çš„äº‹ä»¶çŠ¶æ€");

    Ok(())
}

#[cfg(not(feature = "streaming"))]
fn main() {
    println!("âŒ éœ€è¦å¯ç”¨ 'streaming' åŠŸèƒ½æ‰èƒ½è¿è¡Œæ­¤ç¤ºä¾‹");
    println!("   è¯·ä½¿ç”¨: cargo run --example anthropic_streaming --features streaming");
}