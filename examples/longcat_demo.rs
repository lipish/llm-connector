//! LongCat API Demo
//!
//! This example demonstrates how to use LongCat API with llm-connector.
//!
//! LongCat (https://longcat.chat) is a Chinese LLM API platform that provides:
//! - OpenAI-compatible API format
//! - Anthropic-compatible API format
//! - Free daily quota: 500,000 tokens (can be increased to 5,000,000)
//! - Models: LongCat-Flash-Chat, LongCat-Flash-Thinking
//!
//! ## Setup
//!
//! 1. Register at https://longcat.chat/platform/
//! 2. Get your API key from the API Keys page
//! 3. Set environment variable: export LONGCAT_API_KEY="your-api-key"
//!
//! ## Usage
//!
//! ```bash
//! cargo run --example longcat_demo
//! ```

use llm_connector::{
    config::ProviderConfig,
    protocols::{
        core::{GenericProvider, Provider},
        factory::ProtocolFactoryRegistry,
        openai::longcat,
    },
    types::{ChatRequest, Message},
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ± LongCat API Demo");
    println!("===================\n");

    // Get API key from environment
    let api_key = std::env::var("LONGCAT_API_KEY").unwrap_or_else(|_| {
        println!("âš ï¸  LONGCAT_API_KEY not set, using demo key");
        "demo-key".to_string()
    });

    // ============================================================================
    // Method 1: Direct Protocol Usage
    // ============================================================================
    println!("ğŸ“‹ Method 1: Direct Protocol Usage");
    println!("   Using longcat() function directly\n");

    let config = ProviderConfig::new(&api_key).with_timeout_ms(30000);

    let provider = GenericProvider::new(config.clone(), longcat())?;

    println!("   âœ… Provider created");
    println!("   â”œâ”€ Name: {}", provider.name());
    println!("   â”œâ”€ Base URL: https://api.longcat.chat/openai");
    println!("   â””â”€ Models: {:?}\n", provider.supported_models());

    // ============================================================================
    // Method 2: Factory Pattern
    // ============================================================================
    println!("ğŸ“‹ Method 2: Factory Pattern");
    println!("   Using ProtocolFactoryRegistry\n");

    let registry = ProtocolFactoryRegistry::with_defaults();

    // Check if longcat is registered
    if let Some(protocol) = registry.get_protocol_for_provider("longcat") {
        println!("   âœ… LongCat registered in factory");
        println!("   â”œâ”€ Protocol: {}", protocol);
        println!("   â””â”€ Provider: longcat\n");
    }

    // ============================================================================
    // Supported Models
    // ============================================================================
    println!("ğŸ“‹ Supported Models");
    println!("===================\n");

    println!("   1. LongCat-Flash-Chat");
    println!("      â”œâ”€ Type: General conversation model");
    println!("      â”œâ”€ Performance: High-speed responses");
    println!("      â””â”€ Use case: Chat, Q&A, general tasks\n");

    println!("   2. LongCat-Flash-Thinking");
    println!("      â”œâ”€ Type: Deep thinking model");
    println!("      â”œâ”€ Performance: More thorough reasoning");
    println!("      â””â”€ Use case: Complex problems, analysis\n");

    // ============================================================================
    // Example Request
    // ============================================================================
    println!("ğŸ“‹ Example Request");
    println!("==================\n");

    let request = ChatRequest {
        model: "LongCat-Flash-Chat".to_string(),
        messages: vec![Message::user("ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LongCatã€‚")],
        max_tokens: Some(1000),
        temperature: Some(0.7),
        top_p: None,
        stop: None,
        tools: None,
        tool_choice: None,
        frequency_penalty: None,
        logit_bias: None,
        presence_penalty: None,
        response_format: None,
        seed: None,
        user: None,
        stream: None,
    };

    println!("   Request:");
    println!("   â”œâ”€ Model: {}", request.model);
    println!("   â”œâ”€ Messages: {} message(s)", request.messages.len());
    println!("   â”œâ”€ Max tokens: {:?}", request.max_tokens);
    println!("   â””â”€ Temperature: {:?}\n", request.temperature);

    // Note: Actual API call would be made here
    println!("   â„¹ï¸  To make actual API calls:");
    println!("   1. Set LONGCAT_API_KEY environment variable");
    println!("   2. Uncomment the API call code below\n");

    // Make actual API call:
    match provider.chat(&request).await {
        Ok(response) => {
            println!("   âœ… Response received:");
            if let Some(choice) = response.choices.first() {
                println!("   {}\n", choice.message.content);
            }
            if let Some(usage) = response.usage {
                println!("   Token usage:");
                println!("   â”œâ”€ Prompt: {}", usage.prompt_tokens);
                println!("   â”œâ”€ Completion: {}", usage.completion_tokens);
                println!("   â””â”€ Total: {}", usage.total_tokens);
            }
        }
        Err(e) => {
            println!("   âŒ Error: {}", e);
        }
    }

    // ============================================================================
    // API Features
    // ============================================================================
    println!("ğŸ“‹ API Features");
    println!("===============\n");

    println!("   âœ… OpenAI-compatible format");
    println!("   âœ… Anthropic-compatible format");
    println!("   âœ… Free daily quota: 500,000 tokens");
    println!("   âœ… Can increase to: 5,000,000 tokens/day");
    println!("   âœ… Streaming support");
    println!("   âœ… Rate limiting: Automatic retry recommended\n");

    // ============================================================================
    // Rate Limiting
    // ============================================================================
    println!("ğŸ“‹ Rate Limiting");
    println!("================\n");

    println!("   When rate limited (HTTP 429):");
    println!("   {{");
    println!("     \"error\": {{");
    println!("       \"code\": \"rate_limit_exceeded\",");
    println!("       \"message\": \"è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•\",");
    println!("       \"type\": \"rate_limit_error\",");
    println!("       \"retry_after\": 60");
    println!("     }}");
    println!("   }}\n");

    println!("   ğŸ’¡ Recommendation: Use RetryMiddleware");
    println!("   ```rust");
    println!("   use llm_connector::middleware::RetryMiddleware;");
    println!("   let retry = RetryMiddleware::default();");
    println!("   retry.execute(|| provider.chat(&request)).await?;");
    println!("   ```\n");

    // ============================================================================
    // Configuration Examples
    // ============================================================================
    println!("ğŸ“‹ Configuration Examples");
    println!("=========================\n");

    println!("   1. Basic Configuration:");
    println!("   ```rust");
    println!("   let config = ProviderConfig::new(\"your-api-key\");");
    println!("   let provider = GenericProvider::new(config, longcat())?;");
    println!("   ```\n");

    println!("   2. With Retry:");
    println!("   ```rust");
    println!("   use llm_connector::config::RetryConfig;");
    println!("   let config = ProviderConfig::new(\"your-api-key\")");
    println!("       .with_retry(RetryConfig::default());");
    println!("   ```\n");

    println!("   3. With Custom Headers:");
    println!("   ```rust");
    println!("   let config = ProviderConfig::new(\"your-api-key\")");
    println!("       .with_header(\"X-Request-ID\", \"12345\");");
    println!("   ```\n");

    // ============================================================================
    // Links
    // ============================================================================
    println!("ğŸ“‹ Useful Links");
    println!("===============\n");

    println!("   ğŸŒ Platform: https://longcat.chat/platform/");
    println!("   ğŸ“š Documentation: https://longcat.chat/platform/docs/zh/");
    println!("   ğŸ”‘ API Keys: https://longcat.chat/platform/api-keys");
    println!("   ğŸ“Š Usage: https://longcat.chat/platform/usage\n");

    // ============================================================================
    // Summary
    // ============================================================================
    println!("ğŸ“‹ Summary");
    println!("==========\n");

    println!("   âœ… LongCat support added to llm-connector");
    println!("   âœ… Compatible with OpenAI protocol");
    println!("   âœ… Easy to use with existing code");
    println!("   âœ… Free daily quota available");
    println!("   âœ… Production-ready with retry support\n");

    println!("âœ¨ LongCat Demo Complete!");

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use llm_connector::protocols::core::ProviderAdapter;

    #[test]
    fn test_longcat_protocol() {
        let protocol = longcat();
        assert_eq!(protocol.name(), "longcat");
        assert_eq!(protocol.supported_models().len(), 2);
        assert!(protocol
            .supported_models()
            .contains(&"LongCat-Flash-Chat".to_string()));
        assert!(protocol
            .supported_models()
            .contains(&"LongCat-Flash-Thinking".to_string()));
    }

    #[test]
    fn test_longcat_in_factory() {
        let registry = ProtocolFactoryRegistry::with_defaults();
        let protocol = registry.get_protocol_for_provider("longcat");
        assert_eq!(protocol, Some("openai".to_string()));
    }
}
