#[cfg(feature = "streaming")]
use futures_util::StreamExt;
use llm_connector::{LlmClient, types::{ChatRequest, Message, Role, Tool, Function}};
use serde_json::json;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    #[cfg(not(feature = "streaming"))]
    {
        println!("âŒ éœ€è¦å¯ç”¨ 'streaming' åŠŸèƒ½");
        return Ok(());
    }
    
    #[cfg(feature = "streaming")]
    {
        let api_key = std::env::var("ZHIPU_API_KEY")
            .expect("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPU_API_KEY");
        
        let client = LlmClient::zhipu(&api_key)?;
        
        let tools = vec![Tool {
            tool_type: "function".to_string(),
            function: Function {
                name: "get_weather".to_string(),
                description: Some("è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯".to_string()),
                parameters: json!({
                    "type": "object",
                    "properties": {
                        "location": {"type": "string", "description": "åŸå¸‚åç§°"},
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                    },
                    "required": ["location"]
                }),
            },
        }];
        
        let models = vec!["glm-4", "glm-4.5", "glm-4-flash"];
        
        for model in models {
            println!("\n{}", "=".repeat(70));
            println!("ğŸ§ª æµ‹è¯•æ¨¡å‹: {}", model);
            println!("{}\n", "=".repeat(70));
            
            test_first_request(&client, model, &tools).await?;
            println!("\n");
            test_with_tool_result(&client, model, &tools).await?;
        }
    }
    
    Ok(())
}

#[cfg(feature = "streaming")]
async fn test_first_request(
    client: &LlmClient, 
    model: &str, 
    tools: &[Tool]
) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ ç¬¬ä¸€è½®è¯·æ±‚ï¼ˆè§¦å‘å·¥å…·è°ƒç”¨ï¼‰");
    
    let request = ChatRequest {
        model: model.to_string(),
        messages: vec![Message {
            role: Role::User,
            content: "ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ".to_string(),
            ..Default::default()
        }],
        tools: Some(tools.to_vec()),
        ..Default::default()
    };
    
    let mut stream = client.chat_stream(&request).await?;
    let mut has_tool_calls = false;
    let mut content_received = false;
    let mut chunk_count = 0;
    
    while let Some(chunk) = stream.next().await {
        chunk_count += 1;
        match chunk {
            Ok(response) => {
                if let Some(content) = response.get_content() {
                    if !content.trim().is_empty() {
                        content_received = true;
                        print!("{}", content);
                    }
                }
                
                if let Some(choice) = response.choices.first() {
                    if choice.delta.tool_calls.is_some() {
                        has_tool_calls = true;
                    }
                    
                    if let Some(reason) = &choice.finish_reason {
                        println!("\nâœ… finish_reason: {}", reason);
                        break;
                    }
                }
            }
            Err(e) => {
                eprintln!("âŒ æµå¼é”™è¯¯: {}", e);
                break;
            }
        }
    }
    
    println!("\nğŸ“Š ç»Ÿè®¡:");
    println!("  - æ”¶åˆ° {} ä¸ªæµå¼å—", chunk_count);
    println!("  - æ–‡æœ¬å†…å®¹: {}", if content_received { "âœ… æœ‰" } else { "âŒ æ— " });
    println!("  - å·¥å…·è°ƒç”¨: {}", if has_tool_calls { "âœ… æœ‰" } else { "âŒ æ— " });
    
    Ok(())
}

#[cfg(feature = "streaming")]
async fn test_with_tool_result(
    client: &LlmClient, 
    model: &str, 
    tools: &[Tool]
) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ ç¬¬äºŒè½®è¯·æ±‚ï¼ˆåŒ…å« tool ç»“æœï¼‰");
    
    let request = ChatRequest {
        model: model.to_string(),
        messages: vec![
            Message {
                role: Role::User,
                content: "ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ".to_string(),
                ..Default::default()
            },
            Message {
                role: Role::Assistant,
                content: String::new(),
                tool_calls: Some(vec![llm_connector::types::ToolCall {
                    id: "call_123".to_string(),
                    call_type: "function".to_string(),
                    function: llm_connector::types::FunctionCall {
                        name: "get_weather".to_string(),
                        arguments: r#"{"location":"ä¸Šæµ·"}"#.to_string(),
                    },
                }]),
                ..Default::default()
            },
            Message {
                role: Role::Tool,
                content: r#"{"temperature": 22, "condition": "æ™´å¤©"}"#.to_string(),
                tool_call_id: Some("call_123".to_string()),
                name: Some("get_weather".to_string()),
                ..Default::default()
            },
        ],
        tools: Some(tools.to_vec()),
        ..Default::default()
    };
    
    let mut stream = client.chat_stream(&request).await?;
    let mut content_received = false;
    let mut chunk_count = 0;
    
    println!("\nğŸ“¨ å“åº”:");
    while let Some(chunk) = stream.next().await {
        chunk_count += 1;
        match chunk {
            Ok(response) => {
                if let Some(content) = response.get_content() {
                    if !content.trim().is_empty() {
                        content_received = true;
                        print!("{}", content);
                    }
                }
                
                if let Some(choice) = response.choices.first() {
                    if let Some(reason) = &choice.finish_reason {
                        println!("\nâœ… finish_reason: {}", reason);
                        break;
                    }
                }
            }
            Err(e) => {
                eprintln!("âŒ æµå¼é”™è¯¯: {}", e);
                break;
            }
        }
    }
    
    println!("\nğŸ“Š ç»Ÿè®¡:");
    println!("  - æ”¶åˆ° {} ä¸ªæµå¼å—", chunk_count);
    println!("  - æ–‡æœ¬å†…å®¹: {}", if content_received { "âœ… æœ‰" } else { "âš ï¸ æ— ï¼ˆå¯èƒ½è¢«è‡ªåŠ¨åˆ‡æ¢ä¸ºéæµå¼ï¼‰" });
    
    if chunk_count == 1 && content_received {
        println!("\nğŸ’¡ æç¤º: åªæ”¶åˆ° 1 ä¸ªå—ä¸”æœ‰å†…å®¹ï¼Œè¯´æ˜è‡ªåŠ¨åˆ‡æ¢åˆ°äº†éæµå¼æ¨¡å¼ï¼ˆè¿™æ˜¯æ­£ç¡®çš„è¡Œä¸ºï¼‰");
    }
    
    Ok(())
}
