//! Zhipu GLM-Z1 æ¨ç†æ¨¡å‹æµå¼å“åº”æµ‹è¯•
//!
//! æµ‹è¯• Zhipu æ¨ç†æ¨¡å‹çš„æµå¼å“åº”å¤„ç†ï¼ŒéªŒè¯ ###Thinking å’Œ ###Response æ ‡è®°çš„æ­£ç¡®è§£æ

use llm_connector::{LlmClient, types::{ChatRequest, Message, Role}};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ä»ç¯å¢ƒå˜é‡è·å– API key
    let api_key = std::env::var("ZHIPU_API_KEY")
        .expect("ZHIPU_API_KEY environment variable not set");

    println!("ğŸ§ª æµ‹è¯• Zhipu GLM-Z1 æ¨ç†æ¨¡å‹æµå¼å“åº”");
    println!("{}", "=".repeat(80));

    // åˆ›å»ºå®¢æˆ·ç«¯
    let client = LlmClient::zhipu(&api_key)?;

    println!("\nğŸ“ æµ‹è¯• 1: æ¨ç†æ¨¡å‹æµå¼å“åº”ï¼ˆGLM-Z1ï¼‰");
    println!("{}", "-".repeat(80));

    let request = ChatRequest {
        model: "glm-z1".to_string(),
        messages: vec![Message::text(Role::User, "9.11 å’Œ 9.9 å“ªä¸ªæ›´å¤§ï¼Ÿè¯·è¯¦ç»†è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚")],
        stream: Some(true),
        max_tokens: Some(1000),
        ..Default::default()
    };

    println!("\nğŸ“¤ å‘é€æµå¼è¯·æ±‚:");
    println!("   Model: {}", request.model);
    println!("   Message: {}", request.messages[0].content_as_text());
    println!("   Stream: true");

    #[cfg(feature = "streaming")]
    {
        use futures_util::StreamExt;

        println!("\nğŸ“¥ æ¥æ”¶æµå¼å“åº”:");
        println!("{}", "=".repeat(80));

        match client.chat_stream(&request).await {
            Ok(mut stream) => {
                let mut reasoning_content = String::new();
                let mut answer_content = String::new();
                let mut chunk_count = 0;
                let mut reasoning_chunk_count = 0;
                let mut answer_chunk_count = 0;
                let mut in_reasoning = true;

                while let Some(result) = stream.next().await {
                    match result {
                        Ok(chunk) => {
                            chunk_count += 1;

                            // æå–æ¨ç†å†…å®¹
                            if let Some(reasoning) = chunk.choices.first()
                                .and_then(|c| c.delta.reasoning_content.as_ref()) {
                                if in_reasoning {
                                    if reasoning_chunk_count == 0 {
                                        println!("\nğŸ§  æ¨ç†è¿‡ç¨‹:");
                                        println!("{}", "-".repeat(80));
                                    }
                                    print!("{}", reasoning);
                                    use std::io::{self, Write};
                                    io::stdout().flush().unwrap();
                                    reasoning_content.push_str(reasoning);
                                    reasoning_chunk_count += 1;
                                }
                            }

                            // æå–ç­”æ¡ˆå†…å®¹
                            if let Some(content) = chunk.choices.first()
                                .and_then(|c| c.delta.content.as_ref()) {
                                if in_reasoning {
                                    println!("\n\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:");
                                    println!("{}", "-".repeat(80));
                                    in_reasoning = false;
                                }
                                print!("{}", content);
                                use std::io::{self, Write};
                                io::stdout().flush().unwrap();
                                answer_content.push_str(content);
                                answer_chunk_count += 1;
                            }

                            // æå– finish_reason
                            if let Some(reason) = chunk.choices.first()
                                .and_then(|c| c.finish_reason.as_ref()) {
                                println!("\n\nğŸ finish_reason: {}", reason);
                            }

                            // æå– usage
                            if chunk.usage.is_some() {
                                if let Some(u) = chunk.usage {
                                    println!("\nğŸ“Š Usage:");
                                    println!("   prompt_tokens: {}", u.prompt_tokens);
                                    println!("   completion_tokens: {}", u.completion_tokens);
                                    println!("   total_tokens: {}", u.total_tokens);
                                }
                            }
                        }
                        Err(e) => {
                            eprintln!("\nâŒ é”™è¯¯: {}", e);
                            break;
                        }
                    }
                }

                println!("\n{}", "=".repeat(80));
                println!("ğŸ“Š ç»Ÿè®¡:");
                println!("   æ€»æµå¼å—æ•°: {}", chunk_count);
                println!("   æ¨ç†å†…å®¹å—æ•°: {}", reasoning_chunk_count);
                println!("   ç­”æ¡ˆå†…å®¹å—æ•°: {}", answer_chunk_count);
                println!("   æ¨ç†å†…å®¹é•¿åº¦: {} å­—ç¬¦", reasoning_content.len());
                println!("   ç­”æ¡ˆå†…å®¹é•¿åº¦: {} å­—ç¬¦", answer_content.len());

                println!("\nâœ… æµå¼å“åº”æ­£å¸¸ï¼");

                // éªŒè¯
                if reasoning_chunk_count > 0 {
                    println!("\nâœ… æˆåŠŸæå–æ¨ç†å†…å®¹ï¼ˆ###Thinking éƒ¨åˆ†ï¼‰");
                } else {
                    println!("\nâš ï¸  æœªæ£€æµ‹åˆ°æ¨ç†å†…å®¹ï¼ˆå¯èƒ½ä¸æ˜¯æ¨ç†æ¨¡å‹ï¼‰");
                }

                if answer_chunk_count > 0 {
                    println!("âœ… æˆåŠŸæå–ç­”æ¡ˆå†…å®¹ï¼ˆ###Response éƒ¨åˆ†ï¼‰");
                } else {
                    println!("âš ï¸  æœªæ£€æµ‹åˆ°ç­”æ¡ˆå†…å®¹");
                }
            }
            Err(e) => {
                eprintln!("\nâŒ é”™è¯¯: {}", e);
                return Err(e.into());
            }
        }
    }

    #[cfg(not(feature = "streaming"))]
    {
        println!("\nâš ï¸  éœ€è¦å¯ç”¨ 'streaming' feature æ¥æµ‹è¯•æµå¼å“åº”");
        println!("   è¿è¡Œ: cargo run --example test_zhipu_reasoning_stream --features streaming");
    }

    println!("\n\nğŸ“ æµ‹è¯• 2: éæ¨ç†æ¨¡å‹æµå¼å“åº”ï¼ˆGLM-4ï¼‰");
    println!("{}", "-".repeat(80));

    let request = ChatRequest {
        model: "glm-4".to_string(),
        messages: vec![Message::text(Role::User, "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±")],
        stream: Some(true),
        max_tokens: Some(100),
        ..Default::default()
    };

    println!("\nğŸ“¤ å‘é€æµå¼è¯·æ±‚:");
    println!("   Model: {}", request.model);
    println!("   Message: {}", request.messages[0].content_as_text());

    #[cfg(feature = "streaming")]
    {
        use futures_util::StreamExt;

        println!("\nğŸ“¥ æ¥æ”¶æµå¼å“åº”:");
        println!("{}", "-".repeat(80));

        match client.chat_stream(&request).await {
            Ok(mut stream) => {
                let mut full_content = String::new();
                let mut chunk_count = 0;

                while let Some(result) = stream.next().await {
                    match result {
                        Ok(chunk) => {
                            chunk_count += 1;

                            // éæ¨ç†æ¨¡å‹åº”è¯¥åªæœ‰ contentï¼Œæ²¡æœ‰ reasoning_content
                            if let Some(reasoning) = chunk.choices.first()
                                .and_then(|c| c.delta.reasoning_content.as_ref()) {
                                println!("\nâš ï¸  æ„å¤–ï¼šéæ¨ç†æ¨¡å‹è¿”å›äº† reasoning_content: {}", reasoning);
                            }

                            if let Some(content) = chunk.choices.first()
                                .and_then(|c| c.delta.content.as_ref()) {
                                print!("{}", content);
                                use std::io::{self, Write};
                                io::stdout().flush().unwrap();
                                full_content.push_str(content);
                            }
                        }
                        Err(e) => {
                            eprintln!("\nâŒ é”™è¯¯: {}", e);
                            break;
                        }
                    }
                }

                println!("\n\n{}", "-".repeat(80));
                println!("ğŸ“Š ç»Ÿè®¡:");
                println!("   æ€»æµå¼å—æ•°: {}", chunk_count);
                println!("   å®Œæ•´å†…å®¹é•¿åº¦: {} å­—ç¬¦", full_content.len());

                println!("\nâœ… éæ¨ç†æ¨¡å‹æµå¼å“åº”æ­£å¸¸ï¼");
            }
            Err(e) => {
                eprintln!("\nâŒ é”™è¯¯: {}", e);
                return Err(e.into());
            }
        }
    }

    println!("\n{}", "=".repeat(80));
    println!("âœ… Zhipu æ¨ç†æ¨¡å‹æµå¼å“åº”æµ‹è¯•å®Œæˆï¼");
    println!("{}", "=".repeat(80));

    println!("\nğŸ“ æ€»ç»“:");
    println!("   - GLM-Z1 æ¨ç†æ¨¡å‹: è‡ªåŠ¨åˆ†ç¦» ###Thinking å’Œ ###Response");
    println!("   - æ¨ç†å†…å®¹åœ¨ delta.reasoning_content ä¸­");
    println!("   - ç­”æ¡ˆå†…å®¹åœ¨ delta.content ä¸­");
    println!("   - éæ¨ç†æ¨¡å‹: åªæœ‰ delta.contentï¼Œæ²¡æœ‰ reasoning_content");
    println!("   - ç”¨æˆ·ä½“éªŒ: å®æ—¶çœ‹åˆ°æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ");

    Ok(())
}

