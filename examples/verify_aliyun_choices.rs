/// éªŒè¯ Aliyun å“åº”çš„ choices æ•°ç»„
/// 
/// ç¡®è®¤ä¿®å¤å choices æ•°ç»„ä¸ä¸ºç©ºï¼Œå¹¶ä¸”ä¸ content å­—æ®µä¸€è‡´

use llm_connector::{LlmClient, types::{ChatRequest, Message, Role}};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let api_key = std::env::var("ALIYUN_API_KEY")
        .expect("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ALIYUN_API_KEY");
    
    let client = LlmClient::aliyun(&api_key)?;
    
    println!("ğŸ” éªŒè¯ Aliyun å“åº”çš„ choices æ•°ç»„");
    println!("{}", "=".repeat(80));
    
    let request = ChatRequest {
        model: "qwen-turbo".to_string(),
        messages: vec![Message::text(Role::User, "ä½ å¥½")],
        ..Default::default()
    };
    
    println!("\nğŸ“¤ å‘é€è¯·æ±‚...");
    
    let response = client.chat(&request).await?;
    
    println!("\nğŸ“¥ å“åº”ç»“æ„:");
    println!("{}", "-".repeat(80));
    
    // æ£€æŸ¥ choices æ•°ç»„
    println!("\n1. choices æ•°ç»„:");
    println!("   é•¿åº¦: {}", response.choices.len());
    
    if response.choices.is_empty() {
        println!("   âŒ choices æ•°ç»„ä¸ºç©ºï¼");
        println!("   è¿™æ˜¯ä¸€ä¸ª bugï¼Œåº”è¯¥åŒ…å«è‡³å°‘ä¸€ä¸ª choiceã€‚");
        return Err("choices æ•°ç»„ä¸ºç©º".into());
    } else {
        println!("   âœ… choices æ•°ç»„ä¸ä¸ºç©º");
    }
    
    // æ£€æŸ¥ç¬¬ä¸€ä¸ª choice
    if let Some(first_choice) = response.choices.first() {
        println!("\n2. choices[0]:");
        println!("   index: {}", first_choice.index);
        println!("   message.role: {:?}", first_choice.message.role);
        println!("   message.content: {}", first_choice.message.content);
        println!("   finish_reason: {:?}", first_choice.finish_reason);
        
        // æ£€æŸ¥ content å­—æ®µ
        println!("\n3. content ä¾¿åˆ©å­—æ®µ:");
        println!("   content: {}", response.content);
        
        // éªŒè¯ä¸€è‡´æ€§
        println!("\n4. ä¸€è‡´æ€§æ£€æŸ¥:");
        if first_choice.message.content == response.content {
            println!("   âœ… choices[0].message.content == content");
            println!("   ç¬¦åˆè®¾è®¡æ„å›¾ï¼šcontent æ˜¯ä» choices[0] æå–çš„ä¾¿åˆ©å­—æ®µ");
        } else {
            println!("   âŒ choices[0].message.content != content");
            println!("   choices[0].message.content: {}", first_choice.message.content);
            println!("   content: {}", response.content);
            return Err("content å­—æ®µä¸ choices[0] ä¸ä¸€è‡´".into());
        }
    }
    
    // æ£€æŸ¥ usage
    println!("\n5. usage ä¿¡æ¯:");
    if let Some(ref usage) = response.usage {
        println!("   âœ… åŒ…å« usage ä¿¡æ¯");
        println!("   prompt_tokens: {}", usage.prompt_tokens);
        println!("   completion_tokens: {}", usage.completion_tokens);
        println!("   total_tokens: {}", usage.total_tokens);
    } else {
        println!("   âš ï¸  æ²¡æœ‰ usage ä¿¡æ¯");
    }
    
    // æ£€æŸ¥å…¶ä»–å­—æ®µ
    println!("\n6. å…¶ä»–å­—æ®µ:");
    println!("   id: {}", if response.id.is_empty() { "(empty)" } else { &response.id });
    println!("   object: {}", response.object);
    println!("   model: {}", response.model);
    
    println!("\n{}", "=".repeat(80));
    println!("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼");
    println!("\næ€»ç»“:");
    println!("  â€¢ choices æ•°ç»„ä¸ä¸ºç©º");
    println!("  â€¢ choices[0].message.content ä¸ content å­—æ®µä¸€è‡´");
    println!("  â€¢ åŒ…å« usage ä¿¡æ¯");
    println!("  â€¢ ç¬¦åˆ OpenAI æ ‡å‡†æ ¼å¼");
    println!("{}", "=".repeat(80));
    
    Ok(())
}

