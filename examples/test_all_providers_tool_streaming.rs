#[cfg(feature = "streaming")]
use futures_util::StreamExt;
use llm_connector::{LlmClient, types::{ChatRequest, Message, Role, Tool, Function}};
use serde_json::json;
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    #[cfg(not(feature = "streaming"))]
    {
        println!("âŒ éœ€è¦å¯ç”¨ 'streaming' åŠŸèƒ½");
        return Ok(());
    }
    
    #[cfg(feature = "streaming")]
    {
        let tools = vec![Tool {
            tool_type: "function".to_string(),
            function: Function {
                name: "get_weather".to_string(),
                description: Some("Get the current weather in a given location".to_string()),
                parameters: json!({
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string", 
                            "description": "The city name, e.g. San Francisco"
                        },
                        "unit": {
                            "type": "string", 
                            "enum": ["celsius", "fahrenheit"],
                            "description": "Temperature unit"
                        }
                    },
                    "required": ["location"]
                }),
            },
        }];
        
        let mut providers: Vec<(&str, LlmClient, &str)> = Vec::new();
        
        if let Ok(key) = std::env::var("DEEPSEEK_API_KEY") {
            providers.push(("DeepSeek", LlmClient::openai_with_base_url(&key, "https://api.deepseek.com")?, "deepseek-chat"));
        }
        
        if let Ok(key) = std::env::var("ZHIPU_API_KEY") {
            providers.push(("Zhipu GLM-4", LlmClient::zhipu(&key)?, "glm-4"));
            providers.push(("Zhipu GLM-4.5", LlmClient::zhipu(&key)?, "glm-4.5"));
            providers.push(("Zhipu GLM-4-Flash", LlmClient::zhipu(&key)?, "glm-4-flash"));
        }
        
        if let Ok(key) = std::env::var("ALIYUN_API_KEY") {
            providers.push(("Aliyun Qwen", LlmClient::aliyun(&key)?, "qwen-plus"));
        }
        
        let mut results: HashMap<String, TestResult> = HashMap::new();
        
        for (name, client, model) in providers {
            println!("\n{}", "=".repeat(70));
            println!("ğŸ§ª æµ‹è¯• Provider: {}", name);
            println!("   Model: {}", model);
            println!("{}\n", "=".repeat(70));
            
            let result = test_provider(&client, model, &tools).await;
            
            match result {
                Ok(test_result) => {
                    results.insert(name.to_string(), test_result);
                    println!("\nâœ… {} æµ‹è¯•å®Œæˆ", name);
                }
                Err(e) => {
                    println!("\nâŒ {} æµ‹è¯•å¤±è´¥: {}", name, e);
                    results.insert(name.to_string(), TestResult::error());
                }
            }
        }
        
        println!("\n\n{}", "=".repeat(70));
        println!("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»");
        println!("{}\n", "=".repeat(70));
        
        println!("{:<20} | {:^15} | {:^15} | {:^15}", "Provider", "ç¬¬ä¸€è½®æµå¼", "ç¬¬äºŒè½®æµå¼", "éœ€è¦ä¿®å¤");
        println!("{}", "-".repeat(70));
        
        for (name, result) in results.iter() {
            let round1_status = if result.round1_chunks > 1 { "âœ… æ”¯æŒ" } else if result.round1_chunks == 1 { "âš ï¸ å•å—" } else { "âŒ å¤±è´¥" };
            let round2_status = if result.round2_chunks > 1 { "âœ… æ”¯æŒ" } else if result.round2_chunks == 1 { "âš ï¸ å•å—" } else { "âŒ å¤±è´¥" };
            let needs_fix = if result.round2_chunks == 1 && result.round1_chunks > 1 { "âš ï¸ éœ€è¦" } else if result.round2_chunks == 0 { "âŒ å¼‚å¸¸" } else { "âœ… ä¸éœ€è¦" };
            
            println!("{:<20} | {:^15} | {:^15} | {:^15}", name, round1_status, round2_status, needs_fix);
        }
        
        println!("\nğŸ’¡ è¯´æ˜:");
        println!("  - ç¬¬ä¸€è½®æµå¼: ä¸åŒ…å« Role::Tool çš„è¯·æ±‚");
        println!("  - ç¬¬äºŒè½®æµå¼: åŒ…å« Role::Tool çš„è¯·æ±‚");
        println!("  - âœ… æ”¯æŒ: æ”¶åˆ°å¤šä¸ªæµå¼å—");
        println!("  - âš ï¸ å•å—: åªæ”¶åˆ°1ä¸ªå—ï¼ˆå¯èƒ½è¢«å¼ºåˆ¶åˆ‡æ¢ä¸ºéæµå¼ï¼‰");
        println!("  - âš ï¸ éœ€è¦: ç¬¬ä¸€è½®æ”¯æŒæµå¼ï¼Œä½†ç¬¬äºŒè½®è¢«å¼ºåˆ¶åˆ‡æ¢ï¼ˆè¯´æ˜éœ€è¦ workaroundï¼‰");
    }
    
    Ok(())
}

#[derive(Debug)]
struct TestResult {
    round1_chunks: usize,
    round1_has_tool_calls: bool,
    round2_chunks: usize,
    round2_has_content: bool,
}

impl TestResult {
    fn error() -> Self {
        Self {
            round1_chunks: 0,
            round1_has_tool_calls: false,
            round2_chunks: 0,
            round2_has_content: false,
        }
    }
}

#[cfg(feature = "streaming")]
async fn test_provider(
    client: &LlmClient,
    model: &str,
    tools: &[Tool],
) -> Result<TestResult, Box<dyn std::error::Error>> {
    
    println!("ğŸ“ ç¬¬ä¸€è½®è¯·æ±‚ï¼ˆè§¦å‘å·¥å…·è°ƒç”¨ï¼‰");
    
    let request1 = ChatRequest {
        model: model.to_string(),
        messages: vec![Message {
            role: Role::User,
            content: "What's the current weather in San Francisco? Use the get_weather function.".to_string(),
            ..Default::default()
        }],
        tools: Some(tools.to_vec()),
        ..Default::default()
    };
    
    let mut stream1 = client.chat_stream(&request1).await?;
    let mut round1_chunks = 0;
    let mut tool_calls_buffer = Vec::new();
    let mut content_buffer = String::new();
    
    while let Some(chunk) = stream1.next().await {
        round1_chunks += 1;
        match chunk {
            Ok(response) => {
                if let Some(content) = response.get_content() {
                    content_buffer.push_str(content);
                }
                
                if let Some(choice) = response.choices.first() {
                    if let Some(calls) = &choice.delta.tool_calls {
                        tool_calls_buffer.extend(calls.clone());
                    }
                    
                    if let Some(_reason) = &choice.finish_reason {
                        break;
                    }
                }
            }
            Err(e) => {
                println!("âš ï¸ ç¬¬ä¸€è½®æµå¼é”™è¯¯: {}", e);
                break;
            }
        }
    }
    
    println!("  - æ”¶åˆ° {} ä¸ªæµå¼å—", round1_chunks);
    println!("  - å·¥å…·è°ƒç”¨: {}", if !tool_calls_buffer.is_empty() { "âœ… æœ‰" } else { "âŒ æ— " });
    
    if !content_buffer.is_empty() {
        println!("  - å“åº”å†…å®¹é¢„è§ˆ: {}", 
            if content_buffer.len() > 100 { 
                format!("{}...", &content_buffer[..100]) 
            } else { 
                content_buffer.clone() 
            }
        );
    }
    
    if tool_calls_buffer.is_empty() {
        println!("\nâš ï¸ è·³è¿‡ç¬¬äºŒè½®æµ‹è¯•ï¼ˆæœªè§¦å‘å·¥å…·è°ƒç”¨ï¼‰");
        return Ok(TestResult {
            round1_chunks,
            round1_has_tool_calls: false,
            round2_chunks: 0,
            round2_has_content: false,
        });
    }
    
    println!("\nğŸ“ ç¬¬äºŒè½®è¯·æ±‚ï¼ˆåŒ…å« Role::Tool ç»“æœï¼‰");
    
    let first_call = &tool_calls_buffer[0];
    
    let request2 = ChatRequest {
        model: model.to_string(),
        messages: vec![
            Message {
                role: Role::User,
                content: "What's the current weather in San Francisco? Use the get_weather function.".to_string(),
                ..Default::default()
            },
            Message {
                role: Role::Assistant,
                content: String::new(),
                tool_calls: Some(vec![first_call.clone()]),
                ..Default::default()
            },
            Message {
                role: Role::Tool,
                content: r#"{"location":"San Francisco","temperature":18,"unit":"celsius","condition":"sunny","humidity":65}"#.to_string(),
                tool_call_id: Some(first_call.id.clone()),
                name: Some(first_call.function.name.clone()),
                ..Default::default()
            },
        ],
        tools: Some(tools.to_vec()),
        ..Default::default()
    };
    
    let mut stream2 = client.chat_stream(&request2).await?;
    let mut round2_chunks = 0;
    let mut round2_content = String::new();
    
    while let Some(chunk) = stream2.next().await {
        round2_chunks += 1;
        match chunk {
            Ok(response) => {
                if let Some(content) = response.get_content() {
                    round2_content.push_str(content);
                }
                
                if let Some(choice) = response.choices.first() {
                    if let Some(_reason) = &choice.finish_reason {
                        break;
                    }
                }
            }
            Err(e) => {
                println!("âš ï¸ ç¬¬äºŒè½®æµå¼é”™è¯¯: {}", e);
                break;
            }
        }
    }
    
    println!("  - æ”¶åˆ° {} ä¸ªæµå¼å—", round2_chunks);
    println!("  - å“åº”å†…å®¹: {}", if !round2_content.is_empty() { "âœ… æœ‰" } else { "âŒ æ— " });
    
    Ok(TestResult {
        round1_chunks,
        round1_has_tool_calls: true,
        round2_chunks,
        round2_has_content: !round2_content.is_empty(),
    })
}
