//! Test Zhipu streaming timeout issue
//!
//! This example tests the streaming timeout problem with Zhipu GLM API.
//! 
//! Run with:
//! ```bash
//! cargo run --example test_zhipu_streaming_timeout --features streaming
//! ```

use llm_connector::{LlmClient, types::{ChatRequest, Message, Role}};
use futures_util::StreamExt;
use std::time::Instant;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª Testing Zhipu Streaming Timeout Issue\n");
    
    let api_key = "6b4c24a7a3df47a8898b006f9f5c23b6.PXpYUIvTdUU9uKPS";
    
    // Test 1: Non-streaming request (should work)
    println!("ğŸ“ Test 1: Non-streaming request");
    println!("================================");
    test_non_streaming(api_key).await?;
    
    println!("\n");
    
    // Test 2: Streaming request (may timeout)
    println!("ğŸ“ Test 2: Streaming request");
    println!("============================");
    test_streaming(api_key).await?;
    
    Ok(())
}

async fn test_non_streaming(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    let client = LlmClient::zhipu_openai_compatible(api_key)?;
    
    let request = ChatRequest {
        model: "glm-4-flash".to_string(),
        messages: vec![Message::text(Role::User, "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")],
        max_tokens: Some(100),
        stream: Some(false),
        ..Default::default()
    };
    
    let start = Instant::now();
    
    match client.chat(&request).await {
        Ok(response) => {
            let elapsed = start.elapsed();
            println!("âœ… Non-streaming request succeeded");
            println!("â±ï¸  Time: {:?}", elapsed);
            println!("ğŸ“Š Response length: {} chars", response.content.len());
            println!("ğŸ’¬ Content: {}", response.content);
        }
        Err(e) => {
            let elapsed = start.elapsed();
            println!("âŒ Non-streaming request failed");
            println!("â±ï¸  Time: {:?}", elapsed);
            println!("ğŸ”´ Error: {}", e);
            return Err(e.into());
        }
    }
    
    Ok(())
}

async fn test_streaming(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    let client = LlmClient::zhipu_openai_compatible(api_key)?;
    
    let request = ChatRequest {
        model: "glm-4-flash".to_string(),
        messages: vec![Message::text(Role::User, "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")],
        max_tokens: Some(100),
        stream: Some(true),
        ..Default::default()
    };
    
    let start = Instant::now();
    
    match client.chat_stream(&request).await {
        Ok(mut stream) => {
            println!("âœ… Stream created successfully");
            
            let mut chunk_count = 0;
            let mut total_content = String::new();
            let mut first_chunk_time = None;
            
            while let Some(result) = stream.next().await {
                match result {
                    Ok(chunk) => {
                        if first_chunk_time.is_none() {
                            first_chunk_time = Some(start.elapsed());
                            println!("â±ï¸  First chunk received: {:?}", first_chunk_time.unwrap());
                        }
                        
                        chunk_count += 1;
                        
                        if let Some(content) = chunk.get_content() {
                            total_content.push_str(content);
                            print!("{}", content);
                        }
                    }
                    Err(e) => {
                        let elapsed = start.elapsed();
                        println!("\nâŒ Stream error at chunk {}", chunk_count);
                        println!("â±ï¸  Time: {:?}", elapsed);
                        println!("ğŸ”´ Error: {}", e);
                        return Err(e.into());
                    }
                }
            }
            
            let elapsed = start.elapsed();
            println!("\n\nâœ… Stream completed successfully");
            println!("â±ï¸  Total time: {:?}", elapsed);
            println!("ğŸ“Š Total chunks: {}", chunk_count);
            println!("ğŸ“Š Total content length: {} chars", total_content.len());
            
            if chunk_count == 0 {
                println!("âš ï¸  WARNING: Received 0 chunks! This indicates a problem.");
                return Err("No chunks received".into());
            }
        }
        Err(e) => {
            let elapsed = start.elapsed();
            println!("âŒ Failed to create stream");
            println!("â±ï¸  Time: {:?}", elapsed);
            println!("ğŸ”´ Error: {}", e);
            return Err(e.into());
        }
    }
    
    Ok(())
}

