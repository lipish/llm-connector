# Aliyun enable_thinking å‚æ•°æ”¯æŒæ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜æè¿°

Aliyun çš„æ··åˆæ¨ç†æ¨¡å¼éœ€è¦åœ¨è¯·æ±‚ä¸­è®¾ç½® `enable_thinking: true` å‚æ•°æ‰èƒ½å¯ç”¨æ¨ç†å†…å®¹è¿”å›ã€‚

**å®˜æ–¹æ–‡æ¡£**: https://www.alibabacloud.com/help/en/model-studio/deep-thinking

---

## ğŸ¯ å½“å‰çŠ¶æ€

### æ”¯æŒçš„æ¨¡å‹

#### æ··åˆæ¨ç†æ¨¡å¼ï¼ˆéœ€è¦ `enable_thinking: true`ï¼‰
- qwen-plus, qwen-plus-latest
- qwen-flash
- qwen-turbo, qwen-turbo-latest
- qwen3 ç³»åˆ—ï¼ˆqwen3-235b-a22b, qwen3-32b, qwen3-30b-a3b ç­‰ï¼‰
- deepseek-v3.2-exp, deepseek-v3.1

#### çº¯æ¨ç†æ¨¡å¼ï¼ˆé»˜è®¤å¯ç”¨ï¼Œæ— æ³•å…³é—­ï¼‰
- qwen3-next-80b-a3b-thinking
- qwen3-235b-a22b-thinking-2507
- qwen3-30b-a3b-thinking-2507
- qwq-plus, qwq-plus-latest, qwq-plus-2025-03-05, qwq-32b
- deepseek-r1, deepseek-r1-0528
- deepseek-r1 distilled models

### å½“å‰å®ç°

**AliyunParameters** ç»“æ„ä½“ï¼š
```rust
pub struct AliyunParameters {
    pub max_tokens: Option<u32>,
    pub temperature: Option<f32>,
    pub top_p: Option<f32>,
    pub result_format: String,
    pub incremental_output: Option<bool>,
    // âŒ ç¼ºå°‘ enable_thinking å­—æ®µ
}
```

**é—®é¢˜**:
- âŒ æ— æ³•å¯ç”¨æ··åˆæ¨ç†æ¨¡å¼
- âŒ æ··åˆæ¨ç†æ¨¡å‹ä¸ä¼šè¿”å› `reasoning_content`
- âŒ ç”¨æˆ·æ— æ³•ä½¿ç”¨ qwen-plus ç­‰æ¨¡å‹çš„æ¨ç†åŠŸèƒ½

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: æ·»åŠ åˆ° AliyunParametersï¼ˆæ¨èï¼‰â­â­â­â­â­

**åŸç†**: åœ¨ `AliyunParameters` ä¸­æ·»åŠ  `enable_thinking` å­—æ®µ

**å®ç°**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AliyunParameters {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,
    pub result_format: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub incremental_output: Option<bool>,
    
    // æ–°å¢ï¼šå¯ç”¨æ¨ç†æ¨¡å¼
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enable_thinking: Option<bool>,
}
```

**åœ¨ prepare_request ä¸­ä½¿ç”¨**:
```rust
fn prepare_request(&self, request: &ChatRequest) -> Result<Self::Request, LlmConnectorError> {
    // ... ç°æœ‰ä»£ç 
    
    let parameters = AliyunParameters {
        max_tokens: request.max_tokens,
        temperature: request.temperature,
        top_p: request.top_p,
        result_format: "message".to_string(),
        incremental_output: request.stream,
        enable_thinking: None,  // é»˜è®¤ä¸å¯ç”¨
    };
    
    // ...
}
```

**ä¼˜ç‚¹**:
- âœ… ç®€å•ç›´æ¥
- âœ… ç¬¦åˆ Aliyun API è§„èŒƒ
- âœ… å‘åå…¼å®¹

**ç¼ºç‚¹**:
- âš ï¸ ç”¨æˆ·æ— æ³•é€šè¿‡ ChatRequest æ§åˆ¶
- âš ï¸ éœ€è¦é¢å¤–çš„ API æˆ–é…ç½®

---

### æ–¹æ¡ˆ 2: æ·»åŠ åˆ° ChatRequestï¼ˆé€šç”¨ï¼‰â­â­â­â­

**åŸç†**: åœ¨ `ChatRequest` ä¸­æ·»åŠ  `enable_thinking` å­—æ®µï¼Œä½œä¸ºé€šç”¨å‚æ•°

**å®ç°**:
```rust
// src/types/request.rs
pub struct ChatRequest {
    // ... ç°æœ‰å­—æ®µ
    
    /// Enable thinking/reasoning mode (provider-specific)
    /// - Aliyun: Enable reasoning content for hybrid models
    /// - Other providers: May be ignored
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enable_thinking: Option<bool>,
}
```

**åœ¨ Aliyun prepare_request ä¸­ä½¿ç”¨**:
```rust
let parameters = AliyunParameters {
    // ... å…¶ä»–å­—æ®µ
    enable_thinking: request.enable_thinking,
};
```

**ä¼˜ç‚¹**:
- âœ… ç”¨æˆ·å¯ä»¥ç›´æ¥æ§åˆ¶
- âœ… ç»Ÿä¸€çš„ API
- âœ… å…¶ä»– providers å¯ä»¥å¿½ç•¥

**ç¼ºç‚¹**:
- âš ï¸ å¢åŠ äº† ChatRequest çš„å¤æ‚åº¦
- âš ï¸ å¤§å¤šæ•° providers ä¸éœ€è¦æ­¤å‚æ•°

---

### æ–¹æ¡ˆ 3: è‡ªåŠ¨æ£€æµ‹æ¨¡å‹åç§°ï¼ˆæ™ºèƒ½ï¼‰â­â­â­â­â­

**åŸç†**: æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨å¯ç”¨ `enable_thinking`

**å®ç°**:
```rust
fn prepare_request(&self, request: &ChatRequest) -> Result<Self::Request, LlmConnectorError> {
    // è‡ªåŠ¨æ£€æµ‹æ˜¯å¦ä¸ºæ··åˆæ¨ç†æ¨¡å‹
    let enable_thinking = is_hybrid_reasoning_model(&request.model);
    
    let parameters = AliyunParameters {
        // ... å…¶ä»–å­—æ®µ
        enable_thinking: if enable_thinking { Some(true) } else { None },
    };
    
    // ...
}

/// æ£€æµ‹æ˜¯å¦ä¸ºæ··åˆæ¨ç†æ¨¡å‹
fn is_hybrid_reasoning_model(model: &str) -> bool {
    matches!(model,
        "qwen-plus" | "qwen-plus-latest" |
        "qwen-flash" |
        "qwen-turbo" | "qwen-turbo-latest" |
        "qwen3-235b-a22b" | "qwen3-32b" | "qwen3-30b-a3b" |
        "qwen3-14b" | "qwen3-8b" | "qwen3-4b" | "qwen3-1.7b" | "qwen3-0.6b" |
        "deepseek-v3.2-exp" | "deepseek-v3.1"
    )
}
```

**ä¼˜ç‚¹**:
- âœ… ç”¨æˆ·æ— éœ€é…ç½®
- âœ… è‡ªåŠ¨å¯ç”¨æ¨ç†åŠŸèƒ½
- âœ… å‘åå…¼å®¹

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦ç»´æŠ¤æ¨¡å‹åˆ—è¡¨
- âš ï¸ æ–°æ¨¡å‹éœ€è¦æ›´æ–°ä»£ç 

---

### æ–¹æ¡ˆ 4: ç»„åˆæ–¹æ¡ˆï¼ˆæœ€ä½³ï¼‰â­â­â­â­â­

**åŸç†**: ç»“åˆæ–¹æ¡ˆ 2 å’Œæ–¹æ¡ˆ 3

**å®ç°**:
```rust
// 1. æ·»åŠ åˆ° ChatRequestï¼ˆå¯é€‰ï¼‰
pub struct ChatRequest {
    // ... ç°æœ‰å­—æ®µ
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enable_thinking: Option<bool>,
}

// 2. åœ¨ Aliyun prepare_request ä¸­æ™ºèƒ½å¤„ç†
fn prepare_request(&self, request: &ChatRequest) -> Result<Self::Request, LlmConnectorError> {
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å€¼
    let enable_thinking = request.enable_thinking
        .or_else(|| {
            // å¦‚æœç”¨æˆ·æœªæŒ‡å®šï¼Œè‡ªåŠ¨æ£€æµ‹
            if is_hybrid_reasoning_model(&request.model) {
                Some(true)
            } else {
                None
            }
        });
    
    let parameters = AliyunParameters {
        // ... å…¶ä»–å­—æ®µ
        enable_thinking,
    };
    
    // ...
}
```

**ä¼˜ç‚¹**:
- âœ… ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨æ§åˆ¶
- âœ… è‡ªåŠ¨æ™ºèƒ½æ£€æµ‹
- âœ… æœ€ä½³ç”¨æˆ·ä½“éªŒ
- âœ… å‘åå…¼å®¹

**ç¼ºç‚¹**:
- âš ï¸ å®ç°ç¨å¤æ‚

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ç”¨æˆ·æ§åˆ¶ | è‡ªåŠ¨åŒ– | å¤æ‚åº¦ | æ¨èåº¦ |
|------|----------|--------|--------|--------|
| æ–¹æ¡ˆ 1: AliyunParameters | âŒ | âŒ | â­ ä½ | â­â­â­ |
| æ–¹æ¡ˆ 2: ChatRequest | âœ… | âŒ | â­â­ ä¸­ | â­â­â­â­ |
| æ–¹æ¡ˆ 3: è‡ªåŠ¨æ£€æµ‹ | âŒ | âœ… | â­â­ ä¸­ | â­â­â­â­â­ |
| **æ–¹æ¡ˆ 4: ç»„åˆ** | **âœ…** | **âœ…** | **â­â­â­ é«˜** | **â­â­â­â­â­** |

---

## ğŸ¯ æ¨èå®ç°ï¼šæ–¹æ¡ˆ 2ï¼ˆChatRequest å‚æ•°ï¼‰

### å®ç°æ­¥éª¤

#### 1. æ·»åŠ  enable_thinking åˆ° ChatRequest

```rust
// src/types/request.rs
pub struct ChatRequest {
    // ... ç°æœ‰å­—æ®µ
    
    /// Enable thinking/reasoning mode (provider-specific)
    /// 
    /// For Aliyun: Enables reasoning content for hybrid models like qwen-plus
    /// For other providers: May be ignored
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enable_thinking: Option<bool>,
}

impl ChatRequest {
    // ... ç°æœ‰æ–¹æ³•
    
    /// Set enable_thinking parameter
    pub fn with_enable_thinking(mut self, enable: bool) -> Self {
        self.enable_thinking = Some(enable);
        self
    }
}
```

#### 2. æ·»åŠ  enable_thinking åˆ° AliyunParameters

```rust
// src/providers/aliyun.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AliyunParameters {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,
    pub result_format: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub incremental_output: Option<bool>,
    
    /// Enable thinking/reasoning mode for hybrid models
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enable_thinking: Option<bool>,
}
```

#### 3. å®ç°æ¨¡å‹æ£€æµ‹å‡½æ•°

```rust
// src/providers/aliyun.rs

/// æ£€æµ‹æ˜¯å¦ä¸ºæ··åˆæ¨ç†æ¨¡å‹
/// 
/// æ··åˆæ¨ç†æ¨¡å‹éœ€è¦è®¾ç½® enable_thinking=true æ‰èƒ½è¿”å›æ¨ç†å†…å®¹
fn is_hybrid_reasoning_model(model: &str) -> bool {
    matches!(model,
        // Qwen Plus ç³»åˆ—
        "qwen-plus" | "qwen-plus-latest" |
        
        // Qwen Flash
        "qwen-flash" |
        
        // Qwen Turbo ç³»åˆ—
        "qwen-turbo" | "qwen-turbo-latest" |
        
        // Qwen3 ç³»åˆ—
        "qwen3-235b-a22b" | "qwen3-32b" | "qwen3-30b-a3b" |
        "qwen3-14b" | "qwen3-8b" | "qwen3-4b" | "qwen3-1.7b" | "qwen3-0.6b" |
        
        // DeepSeek ç³»åˆ—
        "deepseek-v3.2-exp" | "deepseek-v3.1"
    )
}
```

#### 4. æ›´æ–° prepare_request

```rust
fn prepare_request(&self, request: &ChatRequest) -> Result<Self::Request, LlmConnectorError> {
    // æ™ºèƒ½å¤„ç† enable_thinking
    let enable_thinking = request.enable_thinking
        .or_else(|| {
            // å¦‚æœç”¨æˆ·æœªæŒ‡å®šï¼Œè‡ªåŠ¨æ£€æµ‹
            if is_hybrid_reasoning_model(&request.model) {
                Some(true)
            } else {
                None
            }
        });
    
    let parameters = AliyunParameters {
        max_tokens: request.max_tokens,
        temperature: request.temperature,
        top_p: request.top_p,
        result_format: "message".to_string(),
        incremental_output: request.stream,
        enable_thinking,
    };
    
    // ... å…¶ä½™ä»£ç 
}
```

---

## ğŸ§ª ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æ˜¾å¼å¯ç”¨ï¼ˆæ¨èï¼‰

```rust
// ä½¿ç”¨æ··åˆæ¨ç†æ¨¡å‹ï¼Œæ˜¾å¼å¯ç”¨ enable_thinking
let request = ChatRequest {
    model: "qwen-plus".to_string(),
    messages: vec![Message {
        role: Role::User,
        content: "9.11 å’Œ 9.9 å“ªä¸ªæ›´å¤§ï¼Ÿ".to_string(),
        ..Default::default()
    }],
    enable_thinking: Some(true),  // æ˜¾å¼å¯ç”¨
    ..Default::default()
};

let response = client.chat(&request).await?;

// è¿”å›æ¨ç†å†…å®¹
if let Some(reasoning) = response.reasoning_content {
    println!("æ¨ç†è¿‡ç¨‹: {}", reasoning);
}
println!("ç­”æ¡ˆ: {}", response.content);
```

### ç¤ºä¾‹ 2: æ‰‹åŠ¨æ§åˆ¶

```rust
// æ‰‹åŠ¨å¯ç”¨
let request = ChatRequest {
    model: "qwen-plus".to_string(),
    messages: vec![/* ... */],
    enable_thinking: Some(true),  // æ‰‹åŠ¨å¯ç”¨
    ..Default::default()
};

// æ‰‹åŠ¨ç¦ç”¨
let request = ChatRequest {
    model: "qwen-plus".to_string(),
    messages: vec![/* ... */],
    enable_thinking: Some(false),  // æ‰‹åŠ¨ç¦ç”¨
    ..Default::default()
};
```

### ç¤ºä¾‹ 3: çº¯æ¨ç†æ¨¡å‹ï¼ˆæ— éœ€é…ç½®ï¼‰

```rust
// çº¯æ¨ç†æ¨¡å‹é»˜è®¤å¯ç”¨ï¼Œæ— éœ€é…ç½®
let request = ChatRequest {
    model: "qwq-plus".to_string(),
    messages: vec![/* ... */],
    ..Default::default()
};

let response = client.chat(&request).await?;
// è‡ªåŠ¨è¿”å›æ¨ç†å†…å®¹
```

---

## ğŸ“ æµ‹è¯•è®¡åˆ’

### æµ‹è¯•ç”¨ä¾‹

1. **æ··åˆæ¨ç†æ¨¡å‹ + è‡ªåŠ¨å¯ç”¨**
   - æ¨¡å‹: qwen-plus
   - enable_thinking: Noneï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
   - é¢„æœŸ: è¿”å› reasoning_content

2. **æ··åˆæ¨ç†æ¨¡å‹ + æ‰‹åŠ¨å¯ç”¨**
   - æ¨¡å‹: qwen-plus
   - enable_thinking: Some(true)
   - é¢„æœŸ: è¿”å› reasoning_content

3. **æ··åˆæ¨ç†æ¨¡å‹ + æ‰‹åŠ¨ç¦ç”¨**
   - æ¨¡å‹: qwen-plus
   - enable_thinking: Some(false)
   - é¢„æœŸ: ä¸è¿”å› reasoning_content

4. **çº¯æ¨ç†æ¨¡å‹**
   - æ¨¡å‹: qwq-plus
   - enable_thinking: None
   - é¢„æœŸ: è¿”å› reasoning_contentï¼ˆæ¨¡å‹é»˜è®¤è¡Œä¸ºï¼‰

5. **éæ¨ç†æ¨¡å‹**
   - æ¨¡å‹: qwen-max
   - enable_thinking: None
   - é¢„æœŸ: ä¸è¿”å› reasoning_content

---

## ğŸ¯ æ€»ç»“

**æ¨èæ–¹æ¡ˆ**: æ–¹æ¡ˆ 4ï¼ˆç»„åˆæ–¹æ¡ˆï¼‰

**å®ç°è¦ç‚¹**:
1. âœ… æ·»åŠ  `enable_thinking` åˆ° `ChatRequest`ï¼ˆå¯é€‰å‚æ•°ï¼‰
2. âœ… æ·»åŠ  `enable_thinking` åˆ° `AliyunParameters`
3. âœ… å®ç° `is_hybrid_reasoning_model()` è‡ªåŠ¨æ£€æµ‹
4. âœ… åœ¨ `prepare_request` ä¸­æ™ºèƒ½å¤„ç†

**ç”¨æˆ·ä½“éªŒ**:
- ğŸ¯ **è‡ªåŠ¨åŒ–**: æ··åˆæ¨ç†æ¨¡å‹è‡ªåŠ¨å¯ç”¨
- ğŸ¯ **å¯æ§**: ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è¦†ç›–
- ğŸ¯ **ç®€å•**: å¤§å¤šæ•°æƒ…å†µæ— éœ€é…ç½®
- ğŸ¯ **å…¼å®¹**: å‘åå…¼å®¹ï¼Œä¸å½±å“ç°æœ‰ä»£ç 

**é¢„æœŸæ•ˆæœ**:
- âœ… qwen-plus ç­‰æ¨¡å‹è‡ªåŠ¨è¿”å› reasoning_content
- âœ… ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨æ§åˆ¶æ˜¯å¦å¯ç”¨
- âœ… çº¯æ¨ç†æ¨¡å‹ç»§ç»­æ­£å¸¸å·¥ä½œ
- âœ… éæ¨ç†æ¨¡å‹ä¸å—å½±å“

