# è…¾è®¯äº‘æ··å…ƒï¼ˆTencent Hunyuanï¼‰ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

è…¾è®¯äº‘æ··å…ƒæ˜¯è…¾è®¯å…¬å¸æ¨å‡ºçš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ï¼Œæä¾›å¼ºå¤§çš„å¯¹è¯ã€åˆ›ä½œå’Œç†è§£èƒ½åŠ›ã€‚

- **å®˜ç½‘**: https://cloud.tencent.com/product/hunyuan
- **æ§åˆ¶å°**: https://console.cloud.tencent.com/hunyuan
- **API æ–‡æ¡£**: https://cloud.tencent.com/document/product/1729

## ğŸ¯ API ç‰¹ç‚¹

### å…¼å®¹æ€§

è…¾è®¯äº‘æ··å…ƒä½¿ç”¨ **OpenAI å…¼å®¹çš„ API æ ¼å¼**ï¼š
- ç«¯ç‚¹: `https://api.hunyuan.cloud.tencent.com/v1`
- è®¤è¯: `Authorization: Bearer YOUR_API_KEY`
- æ ¼å¼: ä¸ OpenAI API å®Œå…¨å…¼å®¹

### å¯ç”¨æ¨¡å‹

- **hunyuan-lite**: è½»é‡çº§æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½
- **hunyuan-standard**: æ ‡å‡†æ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
- **hunyuan-pro**: ä¸“ä¸šæ¨¡å‹ï¼Œæ€§èƒ½å¼ºå¤§
- **hunyuan-turbo**: é«˜é€Ÿæ¨¡å‹ï¼Œå“åº”å¿«

## ğŸ”‘ è·å– API Key

### 1. æ³¨å†Œè…¾è®¯äº‘è´¦å·

è®¿é—®: https://cloud.tencent.com

### 2. å¼€é€šæ··å…ƒæœåŠ¡

1. è®¿é—®æ··å…ƒæ§åˆ¶å°: https://console.cloud.tencent.com/hunyuan
2. ç‚¹å‡»"ç«‹å³å¼€é€š"
3. åŒæ„æœåŠ¡åè®®

### 3. åˆ›å»º API Key

1. åœ¨æ§åˆ¶å°ç‚¹å‡»"API å¯†é’¥"
2. ç‚¹å‡»"æ–°å»ºå¯†é’¥"
3. å¤åˆ¶ç”Ÿæˆçš„ API Key
4. æ ¼å¼: `sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`

## ğŸ’» ä½¿ç”¨ llm-connector

### åŸºç¡€ç”¨æ³•

```rust
use llm_connector::{LlmClient, types::{ChatRequest, Message, Role}};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºå®¢æˆ·ç«¯
    let client = LlmClient::openai_compatible(
        "sk-YMiR2Q7LNWVKVWKivkfPn49geQXT27OZXumFkSS3Ef6FlQ50",  // API Key
        "https://api.hunyuan.cloud.tencent.com",  // ç«¯ç‚¹ï¼ˆä¸åŒ…å« /v1ï¼‰
        "tencent"  // æœåŠ¡åç§°
    )?;
    
    // åˆ›å»ºè¯·æ±‚
    let request = ChatRequest {
        model: "hunyuan-lite".to_string(),
        messages: vec![Message {
            role: Role::User,
            content: "ä½ å¥½".to_string(),
            ..Default::default()
        }],
        max_tokens: Some(1000),
        ..Default::default()
    };
    
    // å‘é€è¯·æ±‚
    let response = client.chat(&request).await?;
    println!("Response: {}", response.content);
    
    Ok(())
}
```

### æµå¼å“åº”

```rust
#[cfg(feature = "streaming")]
{
    use futures_util::StreamExt;
    
    let mut streaming_request = request.clone();
    streaming_request.stream = Some(true);
    
    let mut stream = client.chat_stream(&streaming_request).await?;
    while let Some(chunk) = stream.next().await {
        let chunk = chunk?;
        if let Some(content) = chunk.get_content() {
            print!("{}", content);
        }
    }
}
```

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•éæµå¼å“åº”

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export TENCENT_API_KEY="your-api-key"

# è¿è¡Œæµ‹è¯•
cargo run --example test_tencent
```

### æµ‹è¯•æµå¼å“åº”

```bash
cargo run --example test_tencent --features streaming
```

### æµ‹è¯•åŸå§‹ API

```bash
./tests/test_tencent_raw.sh
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. Base URL è®¾ç½®

**é”™è¯¯ç¤ºä¾‹**:
```rust
// âŒ é”™è¯¯ï¼šåŒ…å« /v1 ä¼šå¯¼è‡´ 404
let client = LlmClient::openai_compatible(
    api_key,
    "https://api.hunyuan.cloud.tencent.com/v1",  // é”™è¯¯
    "tencent"
)?;
```

**æ­£ç¡®ç¤ºä¾‹**:
```rust
// âœ… æ­£ç¡®ï¼šä¸åŒ…å« /v1ï¼ŒOpenAI protocol ä¼šè‡ªåŠ¨æ·»åŠ 
let client = LlmClient::openai_compatible(
    api_key,
    "https://api.hunyuan.cloud.tencent.com",  // æ­£ç¡®
    "tencent"
)?;
```

### 2. API Key æ ¼å¼

è…¾è®¯äº‘æ··å…ƒçš„ API Key æ ¼å¼ï¼š
```
sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

ä¸ OpenAI çš„æ ¼å¼ç›¸åŒã€‚

### 3. æ¨¡å‹é€‰æ‹©

æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š
- **å¿«é€Ÿå“åº”**: hunyuan-turbo
- **æˆæœ¬ä¼˜å…ˆ**: hunyuan-lite
- **æ€§èƒ½ä¼˜å…ˆ**: hunyuan-pro
- **å¹³è¡¡é€‰æ‹©**: hunyuan-standard

### 4. å“åº”ä¸­çš„ note å­—æ®µ

è…¾è®¯äº‘æ··å…ƒçš„å“åº”ä¸­åŒ…å«ä¸€ä¸ª `note` å­—æ®µï¼š
```json
{
  "note": "ä»¥ä¸Šå†…å®¹ä¸ºAIç”Ÿæˆï¼Œä¸ä»£è¡¨å¼€å‘è€…ç«‹åœºï¼Œè¯·å‹¿åˆ é™¤æˆ–ä¿®æ”¹æœ¬æ ‡è®°"
}
```

è¿™æ˜¯è…¾è®¯äº‘çš„åˆè§„è¦æ±‚ï¼Œä¸å½±å“æ­£å¸¸ä½¿ç”¨ã€‚

## ğŸ”§ å¸¸è§é”™è¯¯

### é”™è¯¯ 1: HTTP 404

**é”™è¯¯ä¿¡æ¯**:
```
API error: OpenAI HTTP 404:
```

**åŸå› **:
- Base URL è®¾ç½®é”™è¯¯ï¼ŒåŒ…å«äº† `/v1`

**è§£å†³**:
```rust
// ä½¿ç”¨æ­£ç¡®çš„ base_urlï¼ˆä¸åŒ…å« /v1ï¼‰
let client = LlmClient::openai_compatible(
    api_key,
    "https://api.hunyuan.cloud.tencent.com",  // æ­£ç¡®
    "tencent"
)?;
```

### é”™è¯¯ 2: Unauthorized

**é”™è¯¯ä¿¡æ¯**:
```json
{
  "error": {
    "code": "Unauthorized",
    "message": "Invalid API key"
  }
}
```

**åŸå› **:
- API Key æ— æ•ˆæˆ–è¿‡æœŸ

**è§£å†³**:
1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
2. åœ¨æ§åˆ¶å°é‡æ–°ç”Ÿæˆ API Key

### é”™è¯¯ 3: Model Not Found

**é”™è¯¯ä¿¡æ¯**:
```json
{
  "error": {
    "code": "model_not_found",
    "message": "The model does not exist"
  }
}
```

**åŸå› **:
- æ¨¡å‹åç§°é”™è¯¯

**è§£å†³**:
ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°ï¼š
- `hunyuan-lite`
- `hunyuan-standard`
- `hunyuan-pro`
- `hunyuan-turbo`

## ğŸ“Š æ”¯æŒçš„åŠŸèƒ½

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| éæµå¼å“åº” | âœ… | å®Œå…¨æ”¯æŒ |
| æµå¼å“åº” | âœ… | å®Œå…¨æ”¯æŒ |
| å‡½æ•°è°ƒç”¨ | âœ… | æ”¯æŒï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰ |
| è§†è§‰ç†è§£ | âœ… | æ”¯æŒï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰ |
| åµŒå…¥ | âœ… | æ”¯æŒ |

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒå˜é‡ç®¡ç†

```bash
# .env æ–‡ä»¶
TENCENT_API_KEY=sk-xxxxxx
TENCENT_MODEL=hunyuan-lite
```

```rust
use std::env;

let api_key = env::var("TENCENT_API_KEY")?;
let model = env::var("TENCENT_MODEL").unwrap_or_else(|_| "hunyuan-lite".to_string());

let client = LlmClient::openai_compatible(
    &api_key,
    "https://api.hunyuan.cloud.tencent.com",
    "tencent"
)?;

let request = ChatRequest {
    model,
    // ...
};
```

### 2. é”™è¯¯å¤„ç†

```rust
match client.chat(&request).await {
    Ok(response) => {
        println!("Success: {}", response.content);
    }
    Err(e) => {
        eprintln!("Error: {}", e);
        // æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å‹é”™è¯¯
        if e.to_string().contains("model_not_found") {
            eprintln!("æç¤º: è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®");
        }
    }
}
```

### 3. è¶…æ—¶è®¾ç½®

```rust
use llm_connector::providers::openai_compatible_with_config;

let provider = openai_compatible_with_config(
    &api_key,
    "https://api.hunyuan.cloud.tencent.com",
    "tencent",
    Some(60),  // 60ç§’è¶…æ—¶
    None
)?;

let client = LlmClient::from_provider(Arc::new(provider));
```

## ğŸ“š å‚è€ƒèµ„æº

- **å®˜æ–¹æ–‡æ¡£**: https://cloud.tencent.com/document/product/1729
- **æ§åˆ¶å°**: https://console.cloud.tencent.com/hunyuan
- **API å‚è€ƒ**: https://cloud.tencent.com/document/product/1729/111007
- **å®šä»·**: https://cloud.tencent.com/document/product/1729/97731

## ğŸ‰ æ€»ç»“

è…¾è®¯äº‘æ··å…ƒä½¿ç”¨ OpenAI å…¼å®¹çš„ API æ ¼å¼ï¼Œå¯ä»¥é€šè¿‡ `LlmClient::openai_compatible()` æ–¹æ³•è½»æ¾æ¥å…¥ã€‚

**å…³é”®ç‚¹**:
1. âœ… ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
2. âœ… ç«¯ç‚¹: `https://api.hunyuan.cloud.tencent.com`ï¼ˆä¸åŒ…å« `/v1`ï¼‰
3. âœ… æ”¯æŒæµå¼å’Œéæµå¼å“åº”
4. âœ… å¤šç§æ¨¡å‹å¯é€‰ï¼ˆlite, standard, pro, turboï¼‰
5. âœ… å®Œå…¨å…¼å®¹ llm-connector

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-18  
**llm-connector ç‰ˆæœ¬**: v0.4.19+

